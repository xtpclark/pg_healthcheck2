{
  "affected_topics_critical": {
    "metric_keywords": ["isr_health", "affected_topics"],
    "rules": [
      {
        "expression": "data.get('percent_under_replicated', 0) > 50",
        "level": "critical",
        "score": 10,
        "reasoning": "Topic '{data.get('topic')}' has {data.get('percent_under_replicated')}% of partitions under-replicated ({data.get('under_replicated_count')}/{data.get('total_partitions')} partitions). This poses a severe risk to data durability and availability.",
        "recommendations": [
          "Immediately investigate why majority of partitions are out of sync",
          "Check broker health and accessibility - verify all brokers are running",
          "Review broker logs for replication errors or disk issues",
          "Do NOT restart affected brokers until replicas are back in sync",
          "Verify network connectivity between all brokers in the cluster"
        ]
      }
    ]
  },
  "affected_topics_warning": {
    "metric_keywords": ["isr_health", "affected_topics"],
    "rules": [
      {
        "expression": "data.get('under_replicated_count', 0) > 0 and data.get('percent_under_replicated', 0) <= 50",
        "level": "high",
        "score": 8,
        "reasoning": "Topic '{data.get('topic')}' has {data.get('under_replicated_count')} under-replicated partitions ({data.get('percent_under_replicated')}% of {data.get('total_partitions')} total). Fault tolerance is reduced for this topic.",
        "recommendations": [
          "Monitor replication lag using kafka.server:type=ReplicaManager metrics",
          "Check for slow brokers - review I/O metrics, CPU usage, and GC pauses",
          "Verify broker capacity and ensure adequate resources",
          "Review retention policies - high retention can cause replication delays",
          "Set up alerts to notify when under-replication persists for > 5 minutes"
        ]
      }
    ]
  }
}
