# config/config.yaml example
db_type: "postgres" # Which database plugin to load

# Report controls
company_name: Your Company Name   # Will be sanitized
report_title: Database Health Check Report
logo_image: MyLogo.svg[900,900] # Path to a logo image (relative to adoc_out/company_name/images)

# PostgreSQL Connection / Settings
host: your_db_host
port: 5432
database: your_db_name
user: your_db_user
password: your_db_password
pgbouncer_cmd: psql -h localhost -p 6432 -U pgbouncer_user pgbouncer # Command for PgBouncer admin access
is_aurora: false            # Set to true if analyzing an AWS RDS Aurora instance (enables boto3 calls for cloudwatch metrics)

# AI Configuration
ai_analyze: true            # Master switch: Set to true to enable AI analysis (whether integrated or offline)
ai_run_integrated: true     # Set to true for AI analysis during main report generation; false for offline processing with offline_ai_processor.py
ai_api_key: "YOUR_AI_API_KEY" # Your AI API key for authentication with the AI endpoint
ai_endpoint: "https://your-ai-api-endpoint.com/v1" # The URL of your AI API (e.g., Google Gemini, OpenAI-compatible proxy)
ai_model: "your-ai-model-name" # The specific AI model to use (e.g., "gemini-2.0-flash", "gpt-4.1")
ai_user: "healthcheck_runner" # Optional: User identifier to send with AI requests for context/logging
ai_user_header: "X-User-ID" # Optional: Custom HTTP header name for ai_user (e.g., for corporate proxies/AIs)
ai_temperature: 0.2         # Controls randomness of AI output. Lower (e.g., 0.2) for more focused, higher (e.g., 0.9) for more creative.
ai_max_output_tokens: 20000  # Maximum number of tokens (words/pieces of words) the AI should generate in its response.
ai_max_prompt_tokens: 20000  # Maximum number of tokens for the prompt plus structured json for analysis. Dynamic prompt generator will trim to fit this budget.
ssl_cert_path: "/path/to/your/custom/cert.pem" # Optional: Path to a custom SSL certificate for verifying AI endpoint (e.g., for corporate proxies)
